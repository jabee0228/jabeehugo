<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>科技 on Jabee&#39;s Blog</title>
    <link>http://localhost:1313/categories/tech/</link>
    <description>Recent content in 科技 on Jabee&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 27 Jun 2025 11:18:42 +0800</lastBuildDate><atom:link href="http://localhost:1313/categories/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NAS 如何融入我的生活：超過 1200 天的深度使用心得</title>
      <link>http://localhost:1313/notes/250627/</link>
      <pubDate>Fri, 27 Jun 2025 11:18:42 +0800</pubDate>
      
      <guid>http://localhost:1313/notes/250627/</guid>
      <description>&lt;p&gt;Jabee我的人生座右銘就是 &lt;strong&gt;資料要備份，Format要謹慎。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一直以來，我都把資料的儲存看作是使用電腦設備最重要也最需要注意的事情，畢竟資料就像紙本資料一樣，需要整理、存放。不同在於使用電腦儲存資料易存也易消失。&lt;/p&gt;</description>
      <content:encoded>&lt;p&gt;Jabee我的人生座右銘就是 &lt;strong&gt;資料要備份，Format要謹慎。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一直以來，我都把資料的儲存看作是使用電腦設備最重要也最需要注意的事情，畢竟資料就像紙本資料一樣，需要整理、存放。不同在於使用電腦儲存資料易存也易消失。&lt;/p&gt;
&lt;p&gt;一場大火燒掉整間屋子的事，有，但機率相當低；手機被我們摔壞的機率卻相當高。&lt;/p&gt;
&lt;p&gt;所以如何儲存資料，我認為是21世紀每個人都要面臨且學會的事情，否則下一個哀嚎說手機突然壞掉，裡面照片全部不見的人可能就是你了！&lt;/p&gt;
&lt;h1 id=&#34;什麼是-nas-&#34;&gt;什麼是 NAS ?&lt;/h1&gt;
&lt;p&gt;NAS 全名為 Network-Attached Storage，從全名可以看出使利用網路來儲存資料。但 NAS 不同於 Google Drive 等線上雲端硬碟服務，NAS 會是一台真實的設備，放在你家，當開機的時候才可以使用。&lt;/p&gt;
&lt;p&gt;白話文講就是 NAS 就像你自己架的 Google Drive，不過功能更多、更強大，而且不用月費！也就是你能存多少就完全取決你買多大的硬碟裝在 NAS 上了&lt;/p&gt;
&lt;p&gt;不用月費就可以儲存上 TB 甚至 PB 的資料，你心動了嗎？ 先別急，我們先來說說缺點吧！&lt;/p&gt;
&lt;h1 id=&#34;nas-與雲端硬碟的優缺點對比&#34;&gt;NAS 與雲端硬碟的優缺點對比&lt;/h1&gt;
&lt;h2 id=&#34;需要有放的地方&#34;&gt;需要有放的地方&lt;/h2&gt;
&lt;p&gt;前面有提到 NAS 就是一台裝置（電腦），所以你需要有一個地方來放這台裝置，根據你買的型號，需要的大小也不同。最小的 2-Bay （兩顆硬碟位）機型大概也可能比兩台 Mac studio 大台，畢竟兩顆 3.5 寸硬碟也不小，還要加上主機板的大小。另外，通常 NAS 都不會有無線網卡（雖然群暉有提供驅動，但我相當不推薦用 Wifi），意味著你擺放的位置需要原本就有辦法接 RJ45。&lt;/p&gt;
&lt;h2 id=&#34;電費問題&#34;&gt;電費問題&lt;/h2&gt;
&lt;p&gt;通常我們為了隨時隨地可以取資料，NAS 開機就不會再關機了（除了在試東西的時候）。如果你購買的是品牌機 NAS 像是群暉等等的，而且硬碟數在兩顆，那估計不用考慮電費。這種 CPU 功耗想當低，就算常常在使用 NAS 一個月的電費應該也不會超過 100。但如果不是，你可能就要算一下電費。&lt;/p&gt;
&lt;h2 id=&#34;傳統硬碟不貴但需要一段時間就要買新的&#34;&gt;傳統硬碟不貴，但需要一段時間就要買新的&lt;/h2&gt;
&lt;p&gt;回想10年前我們在玩 GTA5，一個遊戲要 100G 的空間，當年有 128G 的 SSD 就相當有實力了，但如今隨便一個線上射擊遊戲就是 50G 起跳甚至100G。&lt;/p&gt;
&lt;p&gt;你說那是遊戲，遊戲又不需要儲存，那我再舉一個例子：十年前的頂級全畫幅相機 Sony A7 一張照片大概在 30MB 左右，如今哈蘇中畫幅一張照片都上百 MB 的。&lt;/p&gt;
&lt;p&gt;現在要買 1TB 的傳統硬碟都快要買不到了，隨著時間，我們儲存的資料也越來越大，所以你現在買10TB 看似很夠用，但三年後呢？&lt;/p&gt;
&lt;p&gt;另外，通常使用 NAS 會至少組 RAID1，也就是你要買兩顆 10TB 的硬碟才能存 10TB，算上每 3-4年升級一次，費用絕非雲端硬碟的月費價格可以負擔的！&lt;/p&gt;
&lt;aside&gt;
💡
&lt;p&gt;什麼是 RAID1？&lt;/p&gt;
&lt;p&gt;雖然傳統硬碟並不像 SSD 有讀取寫入次數，但還是有機率會壞軌，像是因為針頭刮傷盤面等等的可能性，一但刮傷的部分就無法讀取，所以會有一些方式來保證資料安全。&lt;/p&gt;
&lt;p&gt;RAID1 會同時將資料送進兩顆硬碟中，所以當硬碟一顆壞掉時，另一顆硬碟還可以救援。所以也有一些玄學表示組RAID1 要用兩個不同批型號的硬碟，避免同時兩顆壞掉。&lt;/p&gt;
&lt;/aside&gt;
&lt;h2 id=&#34;噪音問題&#34;&gt;噪音問題&lt;/h2&gt;
&lt;p&gt;通常會將 NAS 放在客廳中就是因為傳統硬碟在隨機讀取的聲音其實很大，尤其是夜深人靜的時候。所以你大概率無法把 NAS 放在需要寧靜的地方。&lt;/p&gt;
&lt;p&gt;基本上以上的問題你都 ok，那接著下一步就可以來挑硬體了。&lt;/p&gt;
&lt;h1 id=&#34;nas-主機&#34;&gt;NAS 主機&lt;/h1&gt;
&lt;p&gt;NAS 大致就分兩種：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;品牌機&lt;/li&gt;
&lt;li&gt;自組&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你對網路以及 Linux 不太熟悉的話，相當建議就選品牌機。若有點概念，想省點錢，再來考慮自組。&lt;/p&gt;
&lt;h2 id=&#34;品牌機&#34;&gt;品牌機&lt;/h2&gt;
&lt;p&gt;目前市面上品牌機我認為也不多，你能常看到的就以下幾個：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;群暉&lt;/li&gt;
&lt;li&gt;QNAP&lt;/li&gt;
&lt;li&gt;華芸&lt;/li&gt;
&lt;li&gt;綠聯&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;群暉就是首選&#34;&gt;群暉就是首選&lt;/h3&gt;
&lt;p&gt;我會建議，首選群暉。雖然除了群暉以外我都沒用過，但通常聽到我有朋友買非群暉的 NAS，都是直搖頭。&lt;/p&gt;
&lt;p&gt;群暉到底有沒有料，我認為我自己從高中用到現在，算是相當穩定，一次開機大概就是半年以上。在功能上，也是相當齊全，但這完全是建立在我用的到的情況，文章最後我會分享我用到的功能。&lt;/p&gt;
&lt;h2 id=&#34;自組&#34;&gt;自組&lt;/h2&gt;
&lt;p&gt;自組 NAS 在 2025 的可用性其實已經相當高了。目前開源的項目比較大的就是 TrueNAS，而閉源但免費的項目也有 FnOS。其實現在回想起來當初堅決不用 TrueNAS 的原因比較大是因為沒有完整好用的照片系統（最重要的是要支援 iOS）。不過目前這個也有解，可以採用 Immich 來進行相片管理，也有 iOS 的 APP。而 FnOS 也有自己的相片管理，也支援 iOS，不過短時間我也不會轉，因為目前用的挺穩定。此外，也有所謂的 X群暉，但這個遊走在法律灰色地帶，所以 Jabee 我不鼓勵也不支持。&lt;/p&gt;
&lt;h1 id=&#34;群暉的體驗心得&#34;&gt;群暉的體驗心得&lt;/h1&gt;
&lt;h2 id=&#34;相片管理&#34;&gt;相片管理&lt;/h2&gt;
&lt;p&gt;我從 DSM 6 開始使用，當時群暉主打 Moments 相片管理系統，其實已經相當好用，一段時間後升級 DSM 7，並且同時升級成 Synology Photos。目前 DSM 7 最新版本已經不支援 H.265，用蘋果設備的讀者可能就會有點小頭痛。&lt;/p&gt;
&lt;p&gt;2025年的今天，各家手機廠商的相片系統都在捲 AI，而群暉還在用他們用 OpenCV 研發的超級爛辨識，我只能說那個 AI 功能還不如不開（所以我現在沒有在用該功能），除此之外也沒什麼好抱怨的。&lt;/p&gt;
&lt;p&gt;另外網頁版的功能會稍微多一點，可以篩選鏡頭、相機型號、光圈等等，還算方便。但這個功能並沒有辦法在手機上操作。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/250627/image.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;另外照片也可以直接分享給其他 User，這個很方便（但我這台主機也只有我跟我老爸）。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/250627/image1.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;synology-drive&#34;&gt;Synology Drive&lt;/h2&gt;
&lt;p&gt;Synology Drive 可以透過 client 的 App 幫助隨時同步本地資料。&lt;/p&gt;
&lt;p&gt;異地備份對我來說應該是最重要的一件事，以前總是擔心重要的資料會因為硬碟撞到、甚至是主板掛掉導致資料消失，使用異地備份就可以避免這種事情發生。&lt;/p&gt;
&lt;p&gt;不要不信邪，我在 22 年初一天早上起來，正準備打開我的 M1 MacBook Air，才一開蓋顯示兩秒就整台死機，再也打不開。因為現在 SSD 顆粒都直接焊死在主板上，蘋果 Genius Bar 沒有能力幫我把顆粒取下重新裝到保固換新的主板上，所以整台資料全部不見。但我卻幾乎沒有損失資料，因為所有資料都透過 Synology Drive 保存。&lt;/p&gt;
&lt;h2 id=&#34;額外的服務&#34;&gt;額外的服務&lt;/h2&gt;
&lt;p&gt;其實群暉的功能很多，絕對說不完，包含 VM、VPN Server、USB Copy、Download Station ，這些都是我常用的服務。&lt;/p&gt;
&lt;p&gt;另外如果有點動手能力，container manager 可以裝上各大在 Docker Hub 的項目，增添群暉沒有提供的功能，例如 Home Assistant 等等。&lt;/p&gt;
&lt;h1 id=&#34;總結&#34;&gt;總結&lt;/h1&gt;
&lt;p&gt;用了這麼多年的 NAS，我想一種比喻可以說明我對 NAS 的想法：NAS 就如蘋果的裝置，用了就回不去。一方面當然是數 TB 的資料要移轉不太可能了，另一方面是 NAS 真的從根本解決了我很多問題，對我的數據保障有了一個檔次的提升。&lt;/p&gt;
&lt;p&gt;我會說如果買 NAS 是用來儲存資料，那就太浪費了，但如果你常常因為沒有輕量的 VPS 可以使用，那買一台 NAS 真的是你的不二選擇。&lt;/p&gt;
</content:encoded>
    </item>
    
    <item>
      <title>DDPM paper notes</title>
      <link>http://localhost:1313/notes/241226/</link>
      <pubDate>Thu, 26 Dec 2024 11:41:33 +0800</pubDate>
      
      <guid>http://localhost:1313/notes/241226/</guid>
      <description>&lt;p&gt;這篇主要是參考李教授的影片，以及網路上的文章，整理的筆記。&lt;/p&gt;
&lt;h1 id=&#34;algorithm-1-training&#34;&gt;Algorithm 1: Training&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/notes/241226/DDPM/image.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;第-1-行repeat&#34;&gt;&lt;strong&gt;第 1 行：&lt;code&gt;repeat&lt;/code&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 開始一個迭代訓練過程，直到模型收斂&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-2-行&#34;&gt;&lt;strong&gt;第 2 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 從數據分佈 中取一個樣本 (x0)（即從訓練數據集中抽取一個數據點）。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;x0 代表 clean Image&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;q(x0)：&lt;/strong&gt; 數據分佈，即訓練集中數據的真實分佈。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-3-行&#34;&gt;&lt;strong&gt;第 3 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 隨機選擇一個時間t。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-4-行&#34;&gt;&lt;strong&gt;第 4 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 取一個隨機噪聲樣本 。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解釋：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;擴散過程中，數據會逐步被加上噪聲，最終變成完全隨機的高斯噪聲。&lt;/li&gt;
&lt;li&gt;在訓練過程中，需要用隨機噪聲模擬這個擴散過程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-5-行梯度下降更新&#34;&gt;&lt;strong&gt;第 5 行：梯度下降更新&lt;/strong&gt;&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;∇_θ ‖ε − ε_θ(√ᾱ_t x_0 + √(1−ᾱ_t) ε, t)‖²
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;細節解釋：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ε 為原始噪聲&lt;/p&gt;</description>
      <content:encoded>&lt;p&gt;這篇主要是參考李教授的影片，以及網路上的文章，整理的筆記。&lt;/p&gt;
&lt;h1 id=&#34;algorithm-1-training&#34;&gt;Algorithm 1: Training&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;第-1-行repeat&#34;&gt;&lt;strong&gt;第 1 行：&lt;code&gt;repeat&lt;/code&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 開始一個迭代訓練過程，直到模型收斂&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-2-行&#34;&gt;&lt;strong&gt;第 2 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 從數據分佈 中取一個樣本 (x0)（即從訓練數據集中抽取一個數據點）。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;x0 代表 clean Image&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;q(x0)：&lt;/strong&gt; 數據分佈，即訓練集中數據的真實分佈。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-3-行&#34;&gt;&lt;strong&gt;第 3 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 隨機選擇一個時間t。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-4-行&#34;&gt;&lt;strong&gt;第 4 行&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 取一個隨機噪聲樣本 。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解釋：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;擴散過程中，數據會逐步被加上噪聲，最終變成完全隨機的高斯噪聲。&lt;/li&gt;
&lt;li&gt;在訓練過程中，需要用隨機噪聲模擬這個擴散過程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-5-行梯度下降更新&#34;&gt;&lt;strong&gt;第 5 行：梯度下降更新&lt;/strong&gt;&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;∇_θ ‖ε − ε_θ(√ᾱ_t x_0 + √(1−ᾱ_t) ε, t)‖²
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;細節解釋：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ε 為原始噪聲&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ε_θ(√ᾱ_t x_0 + √(1−ᾱ_t) ε, t) 這一段做的則是 noise predictor。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而 noise predictor 會有以下兩個 input&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;input 1. √ᾱ_t x_0 + √(1−ᾱ_t) ε ; input 2. t 代表第幾個回合的 回合越後面，加上的噪聲越多。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image1.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;√ᾱ_t x_0 + √(1−ᾱ_t) ε ：這邊 ᾱ_t 是根據 Unuiform 出來的 t ，如果 t 值越大，ᾱ_t 越小。 ᾱ_t 越小，代表加上的噪聲比例則越多（右邊乘上的√(1−ᾱ_t)）。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;目標：&lt;/strong&gt; 最小化 ，即讓模型輸出的噪聲與實際加入的噪聲越接近越好。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;梯度下降：&lt;/strong&gt; 對模型的損失函數進行梯度下降，更新參數 。利用 MSE 平均平方差損失去算 梯度下降率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第-6-行until-converged&#34;&gt;&lt;strong&gt;第 6 行：&lt;code&gt;until converged&lt;/code&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 持續迭代，直到模型訓練收斂。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;algorithm-2-sampling&#34;&gt;Algorithm 2: Sampling&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image2.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;第一行-給訂一個-x-大-t-純雜訊圖&#34;&gt;&lt;strong&gt;第一行 給訂一個 X 大 T 純雜訊圖&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意義&lt;/strong&gt;：從標準高斯分佈（均值為 0，方差為 1）中隨機生成一個噪聲樣本作為起始點。&lt;/li&gt;
&lt;li&gt;X 大 T 代表的是 &lt;strong&gt;純雜訊圖&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第二行-迴圈開始&#34;&gt;&lt;strong&gt;第二行 迴圈開始&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;從純噪聲一路 Sampling 到 生成圖&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意義&lt;/strong&gt;：從時間t（最純的噪聲）開始，逐步回溯到 （逐漸去噪直到還原出清晰的數據）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第三行-噪聲條件&#34;&gt;&lt;strong&gt;第三行 噪聲條件&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意義&lt;/strong&gt;：在 Sampling 階段，會在做完減去 Noise predictor 後，再加上 z 噪聲（請看第四行）
&lt;ul&gt;
&lt;li&gt;但在 t == 0 時，已經完成 Sampling ，因此不再加上 z 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第四行&#34;&gt;&lt;strong&gt;第四行&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image3.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;x_{t-1} = (1 / √(a_t)) * (x_t - (1 - a_t) / √(1 - ᾱ_t) * ϵθ(x_t, t)) + σ_t * z&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;詳見：Sampling 階段 Denoise function 化簡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分解理解&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;ϵθ(x_t, t)：Noise predicotr 根據當前 t (哪一階段) 生成噪聲&lt;/li&gt;
&lt;li&gt;(x_t - (1 - a_t) / √(1 - ᾱ_t) * ϵθ(x_t, t)：從當前數據中減去預測的噪聲部分。
&lt;ol&gt;
&lt;li&gt;x_t 代表的則是上一階段的結果，因此 = 右邊是x_{t-1} ，也就是逐步 Sample 到 x0 （clean image）。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;(1 / √(a_t))：（乘號左邊）調整信號幅度，使其回到正確的分佈範圍。&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;σ_t * z：添加隨機噪聲 ，&lt;strong&gt;模擬反向過程的隨機性&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;目的&lt;/strong&gt;：從當前的t還原到上一個t 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image4.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第五行-迴圈結束&#34;&gt;&lt;strong&gt;第五行 迴圈結束&lt;/strong&gt;&lt;/h3&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第六行-最終輸出&#34;&gt;&lt;strong&gt;第六行 最終輸出&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意義&lt;/strong&gt;：當迴圈結束時，輸出最後的結果 ，這就是還原出的清晰數據（如圖像）。
&lt;ul&gt;
&lt;li&gt;x0 代表 clean image，因此 return x0。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image5.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;MLE 的目的是為了讓 Pθ 盡可能的接近於 Pdata。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pθ(x)：model 所 sample 出的 distribution 機率。&lt;/li&gt;
&lt;li&gt;Pdata(x) : 真實世界的 dataset，和 model 的 network 無關。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image6.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;將每一個 sample 出來的 xi 拿 pθ 算出機率 並相乘，竟可能找出最大 θ。&lt;/p&gt;
&lt;p&gt;所以我們要找的 θ 就是機率最高的那一個（LHY 在投影片用 θ* 代表）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;network 的目標是學習數據的規律（真實分佈𝑞(𝑥0)q(x0)），然後模擬這些數據的機率，這就是𝑝𝜃(𝑥0)pθ(x0)。它代表模型認為數據𝑥0x0有多「合理」或「可能」。
*from chatgpt&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image7.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;從log 相乘轉換成 相加log ，相加 log 這樣會近似於 從 pdata 取出的 x ，然後 pθ 算出機率 要越大越好。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image8.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;接著從 expectation 轉換為積分，然後可以算出就等同於 KL(Pdata||Pθ) ，所以我們要找 minimun KL。&lt;/p&gt;
&lt;p&gt;讓 ptheta 讓 pdata的差異最小。&lt;/p&gt;
&lt;h1 id=&#34;vae-compute-pθ&#34;&gt;VAE: Compute pθ&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image9.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;這邊主要是在講說，因為我們不可能去直接看 pθ(x|z) ，因為不可能 sample 出完全一模一樣的圖，這樣會造成 pθ(x|z) = 0。&lt;/p&gt;
&lt;p&gt;因此我們是去看 Mean of Gaussian (去看距離，也就是 x 和 G(z)的距離)。&lt;/p&gt;
&lt;h1 id=&#34;vae-lower-bound-of&#34;&gt;VAE: Lower bound of&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image10.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;≥ 0 是因為 它可以看作 KL divergence 而完全一樣就為0，因此 ≥ 0。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ddpm-compute--pθx&#34;&gt;DDPM: Compute  pθ(x)&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image11.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image12.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;在算 DDPM 時，和 VAE 不同的是， Maximize 期望值時，原先的 Encoder 替換成 Diffusion Process，也就是在加 Noise 的那個階段。&lt;/p&gt;
&lt;p&gt;將式子展開後為以下。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image13.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;從 x1 一直做到 X 大 T&lt;/p&gt;
&lt;h1 id=&#34;單個-qxt--xt-1-算法&#34;&gt;單個 q(XT | XT-1) 算法&lt;/h1&gt;
&lt;p&gt;我們首先要先定義一組 &lt;strong&gt;β1 ~ βT&lt;/strong&gt; ，這組數值為自定義的，類似 Learning rate，會根據修改影響 Network。 因為這會影響在每一 t 加上的噪聲&lt;/p&gt;
&lt;p&gt;（以下李教授有筆誤，應為 Xt = √1-Bt * Xt-1 + √Bt * noise）&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image14.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h1 id=&#34;如果要算出-qxt--x0&#34;&gt;如果要算出 q(XT | X0)&lt;/h1&gt;
&lt;p&gt;其實是可以不用一次一次去把它算出來（不用一步一步把它+上噪聲）。&lt;/p&gt;
&lt;p&gt;從下方可以推導出 q(X2 | X0)&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image15.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image16.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image17.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image18.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;因此 q(Xt | X0) 就可以整理成上圖。&lt;/p&gt;
&lt;h1 id=&#34;噪聲預測&#34;&gt;噪聲預測&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image19.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;從上圖推導至下圖&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image20.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;目標就是去最大化，而為了最大化，也就是盡可能地將 KL Divergence 最小化。（看後面的：KL Divergence between 向前 and 向後）&lt;/p&gt;
&lt;p&gt;算出 KL Divergence 向前 𝑞 ( 𝑥 𝑡 ∣ 𝑥 𝑡 − 1 ) q(x t  ∣x t−1  ) 與向後 𝑃 𝜃 ( 𝑥 𝑡 ∣ 𝑥 𝑡 − 1 ) P θ  (x t  ∣x t−1  ) 的差異。&lt;/p&gt;
&lt;p&gt;$\sum_{t=2}^T E_{q\left(x_t \mid x_0\right)}\left[D_{K L}\left(q\left(x_{t-1} \mid x_t, x_0\right)|| p_\theta\left(x_{t-1} \mid x_t\right)\right]\right.$&lt;/p&gt;
&lt;h2 id=&#34;算出中間xt-1到xt的分佈-qxt-1--xt-x0&#34;&gt;算出中間xt-1到xt的分佈 q(Xt-1 | Xt, X0)&lt;/h2&gt;
&lt;p&gt;前面我們已經講過了，如何算出從 X0 到 Xt，也知道要如何算出 xt-1 到 xt-1 的分佈。&lt;/p&gt;
&lt;p&gt;推倒公式如下&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image21.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image22.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;kl-divergence-between-向前-and-向後&#34;&gt;KL Divergence between 向前 and 向後&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image23.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;因為向前的 Mean 是不可動的，所以我們唯一可動的就是 P(Xt-1|Xt) 的 Mean ，使兩者離中心點的距離最小，這樣一來，就可以使得 KL Divergence 盡可能的小。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image24.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;所以說以上在做的事情也就是訓練 denoise function ，使得它們兩者越相近越好。&lt;/p&gt;
&lt;h1 id=&#34;sampling-階段-denoise-function-化簡&#34;&gt;Sampling 階段 Denoise function 化簡&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241226/DDPM/image25.png&#34; type=&#34;&#34; alt=&#34;image.png&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;原先右上角的式子的 x0 可以根據我們上面已經寫好關於 x0 和 xt 的關係，在帶回去化簡。&lt;/p&gt;
&lt;p&gt;而這邊也就回到 Algorithm Sampling 階段的第四行。&lt;/p&gt;
&lt;h3 id=&#34;ref&#34;&gt;Ref&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cvmart.net/community/detail/7942&#34;&gt;深入浅出扩散模型(Diffusion Model)系列：基石DDPM（人人都能看懂的数学原理篇）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://youtube.com/playlist?list=PLJV_el3uVTsNi7PgekEUFsyVllAJXRsP-&amp;amp;si=_y39Uu28junvh9re&#34;&gt;李弘毅 DDPM&lt;/a&gt;&lt;/p&gt;
</content:encoded>
    </item>
    
    <item>
      <title>Mac OS 無法連上公共網路的解決方法</title>
      <link>http://localhost:1313/notes/241224/</link>
      <pubDate>Tue, 24 Dec 2024 12:13:34 +0800</pubDate>
      
      <guid>http://localhost:1313/notes/241224/</guid>
      <description>&lt;p&gt;今天在桃園圖書館，因為手機訊號不是很好，所以想連 iTaiwan 網路。結果登入的畫面始終就是連不到，相當的納悶。雖然這個情況在 Mac 上面是常態，但我今天怎麼樣就是連不上。查了一下文章，找到簡單的解法如下，以下的方法皆為自己試過可行的。我認為這個可以算是個玄學，因為每個地方 router 設計皆不同，最好的辦法就是多試試。&lt;/p&gt;</description>
      <content:encoded>&lt;p&gt;今天在桃園圖書館，因為手機訊號不是很好，所以想連 iTaiwan 網路。結果登入的畫面始終就是連不到，相當的納悶。雖然這個情況在 Mac 上面是常態，但我今天怎麼樣就是連不上。查了一下文章，找到簡單的解法如下，以下的方法皆為自己試過可行的。我認為這個可以算是個玄學，因為每個地方 router 設計皆不同，最好的辦法就是多試試。&lt;/p&gt;
&lt;h1 id=&#34;解決不了首先重開機&#34;&gt;解決不了首先重開機&lt;/h1&gt;
&lt;p&gt;首先最重要就是先將 cache 清掉，這邊建議直接重開機最快，有機率重開機就會自動跳出。如果重開機還是解決不了，那請繼續往下看。&lt;/p&gt;
&lt;h1 id=&#34;可以試試看-router-的-ip--用可以跳出的裝置的-domain&#34;&gt;可以試試看 Router 的 IP &amp;amp;&amp;amp; 用可以跳出的裝置的 Domain&lt;/h1&gt;
&lt;h2 id=&#34;router-的-ip&#34;&gt;Router 的 IP&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241224/image-20241224122232417.png&#34; type=&#34;&#34; alt=&#34;image-20241224122232417&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;打開設定後點選 wifi 的 detail，可以看到 Router 的 IP address ，有些公共網路的登入會直接設定在 Router ，不過最近比較少見到這種的。&lt;/p&gt;
&lt;h2 id=&#34;使用其他裝置的-domain&#34;&gt;使用其他裝置的 Domain&lt;/h2&gt;
&lt;p&gt;可以借用其他裝置，如果可以跳出登入畫面，那就用該 Domain ，paste 試看看。&lt;/p&gt;
&lt;h1 id=&#34;清除-dns-server&#34;&gt;清除 DNS server&lt;/h1&gt;
&lt;p&gt;以桃園圖書館總館 iTaiwan 為例，若有自定義 DNS server，會導致無法連線。先將 DNS server 清除，並且將 Proxy 關閉，就可以解決。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241224/image-20241224122812679.png&#34; type=&#34;&#34; alt=&#34;image-20241224122812679&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;像我原本就有自定義一個 1.1.1.1 ，先將自定義的按 - 清除掉，接著會跳出灰色字，此為 Router 設定的 DNS Sevrers。接著按 OK 馬上就跳出登入畫面了。&lt;/p&gt;
</content:encoded>
    </item>
    
    <item>
      <title>解決 Pop OS 的手勢捏合 &amp;&amp; Scaling 的問題</title>
      <link>http://localhost:1313/notes/241218/</link>
      <pubDate>Wed, 18 Dec 2024 13:53:21 +0800</pubDate>
      
      <guid>http://localhost:1313/notes/241218/</guid>
      <description>&lt;p&gt;這兩天在重裝 Surface Go 3 的系統，試了幾個，覺得 Pop OS 最符合我的需求，所以開始安裝。&lt;/p&gt;
&lt;p&gt;裝是裝好了，但遇到的問題還不少。趁這個機會記錄一下。&lt;/p&gt;
&lt;h1 id=&#34;gnome-長久以來的-scaling-問題&#34;&gt;Gnome 長久以來的 Scaling 問題&lt;/h1&gt;
&lt;p&gt;Gnome 預設 Scaling 只有 100% &amp;amp;&amp;amp; 200% 可以選擇，這個對 Laptop 用戶來說就比較不友好了，不過解決方法也是比較簡單（就是很勸退剛入門的使用者）。&lt;/p&gt;</description>
      <content:encoded>&lt;p&gt;這兩天在重裝 Surface Go 3 的系統，試了幾個，覺得 Pop OS 最符合我的需求，所以開始安裝。&lt;/p&gt;
&lt;p&gt;裝是裝好了，但遇到的問題還不少。趁這個機會記錄一下。&lt;/p&gt;
&lt;h1 id=&#34;gnome-長久以來的-scaling-問題&#34;&gt;Gnome 長久以來的 Scaling 問題&lt;/h1&gt;
&lt;p&gt;Gnome 預設 Scaling 只有 100% &amp;amp;&amp;amp; 200% 可以選擇，這個對 Laptop 用戶來說就比較不友好了，不過解決方法也是比較簡單（就是很勸退剛入門的使用者）。&lt;/p&gt;
&lt;p&gt;可以用圖形介面的 dcnof Editor 來設定 org.gnome.mutter experimental-features 額外的參數： &amp;lsquo;scale-monitor-framebuffer&amp;rsquo; ，以此開啟小數點的縮放。&lt;/p&gt;
&lt;p&gt;或是在 terminal 輸入：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;gsettings set org.gnome.mutter experimental-features &amp;#34;[&amp;#39;scale-monitor-framebuffer&amp;#39;]&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;正常來說就可以在設定看到更多縮放選項了。&lt;/p&gt;
&lt;h1 id=&#34;無法使用觸控板的手勢和螢幕的觸控手勢&#34;&gt;無法使用觸控板的手勢和螢幕的觸控手勢&lt;/h1&gt;
&lt;p&gt;在裝好的時候，我就發現在 Firefox 中，在觸控板中操作 Pinch zoom in (捏合放大) 無法正常操作，一旦操作捏合，會變成 Ctrl + and Ctrl -，螢幕觸控也無法使用，因此我就開始排查，才 &lt;strong&gt;發現原來 Pop OS 還在使用 X11 而非 Wayland&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;在 Pop OS 從 X11 替換成 Wayland 也很簡單，只要 Enable 就好。&lt;/p&gt;
&lt;p&gt;在 /etc/gdm3/custom.conf 中有一行為&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;WaylandEnable=false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只要將 false 替換成 true 即可。&lt;/p&gt;
&lt;p&gt;接著重啟服務&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo systemctl restart gdm3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;記得再重新登入的時候要在輸入密碼的右下角替換成 Wayland 的環境。&lt;/p&gt;
&lt;p&gt;這樣一來就可以使用捏合了。&lt;/p&gt;
&lt;p&gt;下次再來分享 Surface Go 3 的心得。&lt;/p&gt;
</content:encoded>
    </item>
    
    <item>
      <title>吵得沸沸揚揚的 Mac mini M4 開機按鍵</title>
      <link>http://localhost:1313/notes/241119/</link>
      <pubDate>Tue, 19 Nov 2024 13:34:08 +0800</pubDate>
      
      <guid>http://localhost:1313/notes/241119/</guid>
      <description>&lt;p&gt;最近科技圈鬧得沸沸揚揚的肯定是新 mini 的開機按鍵，大家一直在吵按鍵坐在那邊要確定誒之類的話，但我完全覺得沒什麼。&lt;/p&gt;
&lt;h1 id=&#34;身為麥金塔老用戶&#34;&gt;身為麥金塔老用戶&lt;/h1&gt;
&lt;p&gt;身為 Mac 6 年老用戶，從 high sierra、mojave 到現今的 Sonoma （還沒更新，我都穩定了才會更新），從黑蘋果一路用到白蘋果，一路用到現在。我可以肯定是，我一年主動的關機次數真的是沒有，大約就是一隻手手指可以數得出來。&lt;/p&gt;</description>
      <content:encoded>&lt;p&gt;最近科技圈鬧得沸沸揚揚的肯定是新 mini 的開機按鍵，大家一直在吵按鍵坐在那邊要確定誒之類的話，但我完全覺得沒什麼。&lt;/p&gt;
&lt;h1 id=&#34;身為麥金塔老用戶&#34;&gt;身為麥金塔老用戶&lt;/h1&gt;
&lt;p&gt;身為 Mac 6 年老用戶，從 high sierra、mojave 到現今的 Sonoma （還沒更新，我都穩定了才會更新），從黑蘋果一路用到白蘋果，一路用到現在。我可以肯定是，我一年主動的關機次數真的是沒有，大約就是一隻手手指可以數得出來。&lt;/p&gt;
&lt;h2 id=&#34;為什麼都不關機&#34;&gt;為什麼都不關機&lt;/h2&gt;
&lt;p&gt;其實我也不太能理解為什麼要一直關機，macOS 一直以來在休眠表現都相當的好。從很早開始，蘋果就開始使用 NVRAM，確保在斷電之後的重新啟動可以恢復斷電前的狀態。我記得我在一開始使用的時候，這方面讓我讚嘆不已。畢竟，為了省電（尤其是 Laptop ），休眠還是盡可能的做斷電。以我的 m1 MacBook Air 來說，剛拿到全新的時候，最長有試過用5天都還是可以正常使用。即使不關機，我在和同學的電腦對比起來，我從來不用在考試、圖書館沒插座的時候，去擔心沒有電的問題。（反而是我的 iPhone 整天一直沒電真的很躁）&lt;/p&gt;
&lt;p&gt;所以如果你還在使用 Windows 筆電，然後每次都要打開來的時候開機，關起來的時候關機，就只是為了省電。我可以保證，在 Mac 不會有這個問題。&lt;/p&gt;
&lt;p&gt;另一個層面來想，我真的很討厭，我需要做事的時候，卻要等待開機。用 Mac 回不去的原因就是一個，&lt;strong&gt;這個作業系統整體給我的回應速度是快的&lt;/strong&gt;，我永遠不需要去擔心，當我要做事的時候 -&amp;gt; 按下開機鍵 -&amp;gt; 等 20 秒開機進桌面 -&amp;gt; 等待 30 秒一堆開機自起的應用程式 -&amp;gt; 然後再等待 10 秒開啟你要用的程式，然後開始工作（如果今天你用的不是 pcie 的 ssd，那你可能要把時間再加30秒）。 其實你等待的時間，不只是這些時間，因為這些時間還要再加上額外的因為等太久而去滑手機的時間（其實開機好你還是繼續滑手機）。&lt;/p&gt;
&lt;h1 id=&#34;所以為什麼按鍵做在下面&#34;&gt;所以為什麼按鍵做在下面&lt;/h1&gt;
&lt;p&gt;
  &lt;img loading=&#34;lazy&#34; src=&#34;https://www.apple.com/tw/mac-mini/images/overview/mac-iphone/mac_iphone_mirroring__f420q7238wuy_large.jpg&#34; alt=&#34;銀色 Mac mini 的正面，展示正面連接埠與指示燈；Mac mini 擺放在 Mac 顯示器下方，螢幕上呈現色彩繽紛的畫面以及 Dock 中的多款 app 圖像&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;前面解釋了一堆為什麼不關機，其實也就間接解釋了為什麼按鍵做在下面。因為這個作業系統就是希望你有良好的體驗，不是給你要用才開機，用完就關機的。若是你的手機要用才開機，你還不瘋掉？&lt;/p&gt;
&lt;h2 id=&#34;不是只有-mac-mini-這樣設計&#34;&gt;不是只有 Mac mini 這樣設計&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jabeehugo.netlify.app/notes/241119/DSC00202.jpg_compressed.JPEG&#34; type=&#34;&#34; alt=&#34;&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;其實不止 Mac mini，我有在使用的包含 google nest hub 2、nest mini，都有同樣的設計，更跨張的是，他們甚至沒有開機按鍵，這樣的設計我想就是除了你需要移除裝置之外，不希望你關機。&lt;/p&gt;
&lt;p&gt;所以，對我來說，一個好用的作業系統就是要及時、快速，能不耽誤我的工作，目前真的只有 macOS 能滿足我的體驗。&lt;/p&gt;
</content:encoded>
    </item>
    
  </channel>
</rss>
